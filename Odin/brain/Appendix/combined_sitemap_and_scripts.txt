No comments # in code, don't print the site map. Only show corrected script. Sitemap of Directory: Odin 2
==================================================

[Folder] .
--------------------------------------------------
  C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\config.json
  C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\config.py
  C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\engine.py
  C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\ODIN.bat
  C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\__init__.py

[Folder] brain
--------------------------------------------------
  C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\brain\agenticreason.py
  C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\brain\ai_memory.py
  C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\brain\conversation_manager.py
  C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\brain\file_picker.py
  C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\brain\init.py
  C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\brain\memory_handler.py
  C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\brain\typestreaming.py
  C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\brain\web_agent.py

[Folder] brain\Appendix
--------------------------------------------------
  C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\brain\Appendix\append_scripts.py
  C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\brain\Appendix\launch_project_over_view.bat

[Folder] brain\__pycache__
--------------------------------------------------
  C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\brain\__pycache__\agenticreason.cpython-311.pyc
  C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\brain\__pycache__\ai_memory.cpython-311.pyc
  C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\brain\__pycache__\context_tree.cpython-311.pyc
  C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\brain\__pycache__\conversation_manager.cpython-311.pyc
  C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\brain\__pycache__\file_picker.cpython-311.pyc
  C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\brain\__pycache__\manager.cpython-311.pyc
  C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\brain\__pycache__\memory_handler.cpython-311.pyc
  C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\brain\__pycache__\web_agent.cpython-311.pyc

[Folder] __pycache__
--------------------------------------------------
  C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\__pycache__\config.cpython-311.pyc
  C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\__pycache__\dependencies.cpython-311.pyc
  C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\__pycache__\engine.cpython-311.pyc

==================================================

Script Contents
==================================================

# START OF FILE: C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\config.py
import os
import json

config_path = os.path.join(os.path.dirname(__file__), 'config.json')
with open(config_path, 'r', encoding='utf-8') as config_file:
    config = json.load(config_file)

OPEN_ROUTER_API_KEY = config['OPEN_ROUTER_API_KEY']
MODEL_NAME = config['MODEL_NAME']
# END OF FILE: C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\config.py


# START OF FILE: C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\engine.py
import customtkinter as ctk
from gui.app import run_gui_wrapper
from brain.ai_memory import conversation_manager
from brain.agenticreason import AgenticReasoner
from config import OPEN_ROUTER_API_KEY, MODEL_NAME

ctk.set_appearance_mode("dark")
ctk.set_default_color_theme("blue")

# Set the OpenRouter API key and model name
conversation_manager.set_openrouter_api_key(OPEN_ROUTER_API_KEY)
conversation_manager.set_model_name(MODEL_NAME)

agentic_reasoner = AgenticReasoner(api_key=OPEN_ROUTER_API_KEY, model_name=MODEL_NAME)

def run_engine():
    root = ctk.CTk()
    root.title("Odin")

    screen_width = root.winfo_screenwidth()
    screen_height = root.winfo_screenheight()

    window_width = int(screen_width * 0.25)
    window_height = int(screen_height * 0.85)

    window_x = (screen_width - window_width) // 2
    window_y = (screen_height - window_height) // 2

    root.geometry(f"{window_width}x{window_height}+{window_x}+{window_y}")
    root.configure(fg_color="#000000")

    container = ctk.CTkFrame(root, fg_color="#000000", border_width=0)
    container.pack(padx=20, pady=20, fill=ctk.BOTH, expand=True)

    # Pass the ChatbotUI instance to the ConversationManager
    chatbot_ui = run_gui_wrapper(container)
    conversation_manager.chatbot_ui = chatbot_ui  # Ensure this line is present

    root.mainloop()

if __name__ == "__main__":
    run_engine()
# END OF FILE: C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\engine.py


# START OF FILE: C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\__init__.py

# END OF FILE: C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\__init__.py


# START OF FILE: C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\brain\agenticreason.py
# START OF FILE: C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\brain\agenticreason.py
import os
import json
import logging
import re
from openai import OpenAI as Client
from .conversation_manager import ConversationManager
from .memory_handler import MemoryHandler
from .web_agent import WebAgent

# Set up logging with timestamp and level
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S"
)

class AgenticReasoner:
    def __init__(self, api_key, model_name="gpt-4"):
        """
        Initialize the Agentic Reasoner with an API key and model name.
        """
        self.OPEN_ROUTER_API_KEY = api_key
        self.MODEL_NAME = model_name
        self.client = Client(
            base_url="https://openrouter.ai/api/v1",
            api_key=self.OPEN_ROUTER_API_KEY,
        )
        self.conversation_manager = ConversationManager()
        self.memory_handler = MemoryHandler(self.conversation_manager.memory_dir)
        self.web_agent = WebAgent(self.conversation_manager)
        self.role = None  # Initialize role as None, to be set dynamically
        logging.info("Agentic Reasoner initialized.")

    def is_url(self, text):
        """
        Check if the input text is a URL using a regular expression.
        """
        # Regular expression to detect URLs
        url_pattern = re.compile(
            r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'
        )
        return bool(url_pattern.search(text))

    def process_query(self, user_message):
        """
        Process the user query and generate a response using the AI model.
        """
        # Check if the user message is a URL
        if self.is_url(user_message):
            # Log that a URL was detected
            logging.info("URL detected, scraping content...")

            # Scrape the website content
            scraped_content = self.web_agent.scrape_website_content(user_message)
            if scraped_content:
                # Save the scraped content to the database
                self.conversation_manager.save_to_db(
                    json.dumps(scraped_content, ensure_ascii=False),
                    self.memory_handler.sentence_to_vec(json.dumps(scraped_content)),
                    "website"
                )
                logging.info("Website content scraped and saved to database.")

                # Update the Word2Vec model with the scraped content
                self.memory_handler.update_word2vec_model([scraped_content['text_content'].split()], epochs=10)
                logging.info("Word2Vec model updated with website content.")

                # DO NOT GENERATE A RESPONSE FOR URL SUBMISSIONS
                return None  # No response is generated for URLs
            else:
                logging.error("Failed to scrape the website content.")
                return None  # No response is generated for URLs

        # If it's not a URL, proceed with normal query processing
        # Retrieve previous conversations for context
        previous_conversations = self.conversation_manager.get_previous_conversations()
        if previous_conversations is None:  # Ensure previous_conversations is not None
            previous_conversations = []

        context_messages = [{"role": "system", "content": "You are an AI assistant."}]
        for conv in previous_conversations:
            context_messages.append({"role": "user", "content": conv["user_message"]})
            context_messages.append({"role": "assistant", "content": conv["ai_response"]})

        # Add the current user message
        context_messages.append({"role": "user", "content": user_message})

        # Retrieve the last agentic role from the database
        agentic_role = self.conversation_manager.get_last_agentic_role()
        if agentic_role:
            context_messages.append({"role": "system", "content": f"You are an AI assistant with the role: {agentic_role}."})

        # Generate a response from the AI model
        try:
            completion = self.client.chat.completions.create(
                model=self.MODEL_NAME,
                messages=context_messages,
                extra_headers={"HTTP-Referer": "your_site_url", "X-Title": "your_app_name"}
            )
            if completion.choices and completion.choices[0].message:
                response_message = completion.choices[0].message.content

                # Save the conversation to the database
                self.conversation_manager.save_conversation(
                    f"User: {user_message}\nAI: {response_message}",
                    self.conversation_manager.generate_bulleted_summary(response_message),
                    self.memory_handler.sentence_to_vec(response_message),
                    agentic_role
                )

                return response_message
            else:
                logging.error("Error processing query: No message found in API response.")
                return None
        except Exception as e:
            logging.error(f"Error processing query: {str(e)}")
            return None
# END OF FILE: C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\brain\agenticreason.py
# END OF FILE: C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\brain\agenticreason.py


# START OF FILE: C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\brain\ai_memory.py
import os
import datetime
import numpy as np
import csv
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
from openai import OpenAI as Client
from gensim.models import Word2Vec
from gensim.utils import simple_preprocess
import sqlite3
from .memory_handler import MemoryHandler
from .conversation_manager import ConversationManager

conversation_manager = ConversationManager()

def process_response_with_word2vec(self, response):
    """
    Process the response with Word2Vec for memory and embeddings.
    Returns the embedding vector.
    """
    try:
        # Convert the response to a vector using Word2Vec
        embedding = self.memory_handler.sentence_to_vec(response)
        if embedding:
            logging.info("Response processed with Word2Vec and embedded in memory.")
            return embedding
        else:
            logging.warning("Failed to generate Word2Vec embedding for the response.")
            return None
    except Exception as e:
        logging.error(f"Error processing response with Word2Vec: {str(e)}")
        return None
# END OF FILE: C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\brain\ai_memory.py


# START OF FILE: C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\brain\conversation_manager.py
# START OF FILE: C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\brain\conversation_manager.py
import os
import sqlite3
import logging
import json
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from openai import OpenAI
from .memory_handler import MemoryHandler
import datetime
from bs4 import BeautifulSoup
import requests
import re
from .web_agent import WebAgent  # Import WebAgent
from gensim.utils import simple_preprocess  # Import simple_preprocess

# Set up logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S"
)

class ConversationManager:
    def __init__(self):
        """
        Initialize the ConversationManager with a memory directory and database.
        """
        self.memory_dir = os.path.join(os.path.dirname(__file__), "Memory")
        os.makedirs(self.memory_dir, exist_ok=True)
        self.conv_folder = self.create_conversation_folder()  # Create a new conversation folder
        self.db_path = os.path.join(self.conv_folder, "conversations.db")  # Save .db in the most recent conversation folder
        self.MODEL_NAME = None
        self.OPEN_ROUTER_API_KEY = None
        self.client = None  # Initialize the OpenAI client as None
        self.memory_handler = MemoryHandler(self.conv_folder)  # MemoryHandler uses the conversation folder
        self.web_agent = WebAgent(self)  # Initialize WebAgent
        self.init_db()

    def create_conversation_folder(self):
        """
        Create a new conversation folder with a unique timestamp.
        """
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        conv_folder = os.path.join(self.memory_dir, f"conversation_{timestamp}")
        os.makedirs(conv_folder, exist_ok=True)
        logging.info(f"Created new conversation folder: {conv_folder}")
        return conv_folder

    def init_db(self):
        """
        Initialize the SQLite database for storing embeddings and metadata.
        """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        # Create a single table for all embeddings, with a `source_type` column to indicate the type of content
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS embeddings (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TEXT,
                content TEXT,
                embedding TEXT,
                source_type TEXT  -- e.g., "user_query", "SCRAPED_INFO", "file"
            )
        ''')

        conn.commit()
        conn.close()
        logging.info(f"Database initialized at {self.db_path}")

    def set_openrouter_api_key(self, api_key):
        """
        Set the OpenRouter API key and update the OpenAI client.
        """
        self.OPEN_ROUTER_API_KEY = api_key
        self.update_client()

    def set_model_name(self, model_name):
        """
        Set the model name and update the OpenAI client.
        """
        self.MODEL_NAME = model_name
        self.update_client()

    def update_client(self):
        """
        Update the OpenAI client with the current API key and model name.
        """
        if self.MODEL_NAME and self.OPEN_ROUTER_API_KEY:
            self.client = OpenAI(
                base_url="https://openrouter.ai/api/v1",
                api_key=self.OPEN_ROUTER_API_KEY,
            )
            logging.info("OpenRouter client updated.")
        else:
            logging.warning("OpenRouter client not updated: API key or model name missing.")

    def save_to_db(self, content, embedding, source_type):
        """
        Save content and its embedding to the database.
        - `source_type`: Can be "user_query", "SCRAPED_INFO", or "file".
        """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        cursor.execute('''
            INSERT INTO embeddings (timestamp, content, embedding, source_type)
            VALUES (?, ?, ?, ?)
        ''', (timestamp, content, json.dumps(embedding.tolist()), source_type))

        conn.commit()
        conn.close()
        logging.info(f"Saved {source_type} to the database: {content[:50]}...")  # Log the first 50 chars of content

        # Retrain Word2Vec model after saving new content
        self.retrain_word2vec_model(content)

    def save_chunks_to_db(self, chunks, file_name):
        """
        Save file chunks and their embeddings to the database.
        """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        for chunk in chunks:
            # Generate an embedding for the chunk
            embedding = self.memory_handler.sentence_to_vec(chunk)

            # Save the chunk to the database with source_type as "file"
            cursor.execute('''
                INSERT INTO embeddings (timestamp, content, embedding, source_type)
                VALUES (?, ?, ?, ?)
            ''', (timestamp, chunk, json.dumps(embedding.tolist()), "file"))

        conn.commit()
        conn.close()
        logging.info(f"File chunks saved to the database for file: {file_name}")

    def retrain_word2vec_model(self, new_content):
        """
        Retrain the Word2Vec model with new content.
        """
        try:
            # Tokenize the new content into sentences
            sentences = [simple_preprocess(new_content)]
            # Update the Word2Vec model with the new sentences
            self.memory_handler.update_word2vec_model(sentences)
            logging.info("Word2Vec model retrained with new content.")
        except Exception as e:
            logging.error(f"Error retraining Word2Vec model: {str(e)}")

    def find_most_relevant_content(self, query_embedding, source_type=None):
        """
        Find the most relevant content from the database using cosine similarity.
        - `source_type`: Optional filter to search for specific content types (e.g., "file", "SCRAPED_INFO", "user_query").
        """
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        # Retrieve all embeddings from the database (optionally filtered by source_type)
        if source_type:
            cursor.execute("SELECT content, embedding FROM embeddings WHERE source_type = ?", (source_type,))
        else:
            cursor.execute("SELECT content, embedding FROM embeddings")

        rows = cursor.fetchall()
        conn.close()

        if not rows:
            logging.warning("No content found in the database.")
            return None

        # Calculate cosine similarity between the query and each embedding
        similarities = []
        for row in rows:
            content, embedding_json = row
            embedding = np.array(json.loads(embedding_json))
            similarity = cosine_similarity([query_embedding], [embedding])[0][0]
            similarities.append((content, similarity))

        # Find the most relevant content
        most_relevant_content = max(similarities, key=lambda x: x[1])[0]
        return most_relevant_content

    def process_query(self, user_message):
        """
        Process a user query or URL submission.
        If the input is a URL, delegate scraping to the WebAgent, save the content, and return a response.
        If the input is a query, generate a response using the AI model.
        """
        if self.is_url(user_message):
            # If the input is a URL, delegate scraping to the WebAgent
            logging.info("URL detected, delegating to WebAgent...")
            scraped_content = self.web_agent.scrape_website_content(user_message)
            if scraped_content:
                # Save the scraped content to the database
                self.save_to_db(
                    json.dumps(scraped_content, ensure_ascii=False),
                    self.memory_handler.sentence_to_vec(json.dumps(scraped_content)),
                    "SCRAPED_INFO"
                )
                logging.info("Website content scraped and saved to database.")
                return "The website content has been scraped and saved to memory. How can I assist you further?"
            else:
                logging.error("Failed to scrape the website content.")
                return "Failed to scrape the website content. Please check the URL and try again."
        else:
            # Perform a vector search to find the most relevant content
            query_embedding = self.memory_handler.sentence_to_vec(user_message)
            most_relevant_content = self.find_most_relevant_content(query_embedding)
            if most_relevant_content:
                # Use the OpenAI API to generate a response based on the most relevant content
                try:
                    completion = self.client.chat.completions.create(
                        model=self.MODEL_NAME,
                        messages=[
                            {"role": "system", "content": "You are an AI assistant. Respond naturally and conversationally."},
                            {"role": "user", "content": f"Here is some relevant context:\n\n{most_relevant_content}\n\nUser: {user_message}"}
                        ],
                        extra_headers={"HTTP-Referer": "your_site_url", "X-Title": "your_app_name"}
                    )
                    if completion.choices and completion.choices[0].message:
                        response_message = completion.choices[0].message.content

                        # Save the conversation to the database
                        self.save_to_db(
                            f"User: {user_message}\nAI: {response_message}",
                            self.memory_handler.sentence_to_vec(response_message),
                            "user_query"
                        )

                        return response_message
                    else:
                        logging.error("Error processing query: No message found in API response.")
                        return None
                except Exception as e:
                    logging.error(f"Error processing query: {str(e)}")
                    return None
            else:
                # If no relevant content is found, generate a response using the AI model
                if not self.client:
                    logging.error("OpenAI client is not initialized. Please set the API key and model name.")
                    return "Error: OpenAI client is not initialized. Please set the API key and model name."

                try:
                    completion = self.client.chat.completions.create(
                        model=self.MODEL_NAME,
                        messages=[
                            {"role": "system", "content": "You are an AI assistant. Respond naturally and conversationally."},
                            {"role": "user", "content": user_message}
                        ],
                        extra_headers={"HTTP-Referer": "your_site_url", "X-Title": "your_app_name"}
                    )
                    if completion.choices and completion.choices[0].message:
                        response_message = completion.choices[0].message.content

                        # Save the conversation to the database
                        self.save_to_db(
                            f"User: {user_message}\nAI: {response_message}",
                            self.memory_handler.sentence_to_vec(response_message),
                            "user_query"
                        )

                        return response_message
                    else:
                        logging.error("Error processing query: No message found in API response.")
                        return None
                except Exception as e:
                    logging.error(f"Error processing query: {str(e)}")
                    return None

    def is_url(self, text):
        """
        Check if the input text is a URL using a regular expression.
        """
        url_pattern = re.compile(
            r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'
        )
        return bool(url_pattern.search(text))
# END OF FILE: C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\brain\conversation_manager.py
# END OF FILE: C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\brain\conversation_manager.py


# START OF FILE: C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\brain\file_picker.py
# START OF FILE: C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\brain\file_picker.py
import os
import tkinter as tk
from tkinter import filedialog
import logging
import chardet
import PyPDF2
import docx
import csv
import threading
import customtkinter as ctk
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import re

# Set up logging
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")

class FilePicker:
    def __init__(self, conversation_manager, file_picker_button):
        """
        Initialize the FilePicker with a reference to the ConversationManager and the file picker button.
        """
        self.conversation_manager = conversation_manager
        self.file_picker_button = file_picker_button  # Pass the button from ChatbotButtons
        self.progress_bar = None

    def pick_file(self):
        """
        Open a file dialog to select a file, read its content, and process it as a message.
        """
        root = tk.Tk()
        root.withdraw()
        file_path = filedialog.askopenfilename(title="Select a file to upload")
        if file_path:
            try:
                # Convert the button to a progress bar
                self.file_picker_button.configure(text="Processing...", fg_color="#000000", hover=False)
                self.file_picker_button.update()

                # Process the file in a separate thread
                threading.Thread(target=self.process_file, args=(file_path,)).start()
            except Exception as e:
                logging.error(f"Error processing file: {str(e)}")
                # Display the error message in the chatbot UI
                self.conversation_manager.chatbot_ui.widgets['text_box'].configure(state="normal")
                self.conversation_manager.chatbot_ui.widgets['text_box'].insert('end', f"Error processing file: {str(e)}\n", "assistant")
                self.conversation_manager.chatbot_ui.widgets['text_box'].configure(state="disabled")
                self.conversation_manager.chatbot_ui.widgets['text_box'].yview('end')
                self.restore_button()

    def process_file(self, file_path):
        """
        Process the file into context-aware chunks, generate embeddings, and save them to the database.
        """
        try:
            # Read the file content
            content = self.read_file_content(file_path)
            file_name = os.path.basename(file_path)

            # Split the content into context-aware chunks
            chunks = self.split_into_context_aware_chunks(content)

            # Add file-level identifiers to the first and last chunks
            if chunks:
                # Add start identifier to the first chunk
                chunks[0] = f"--- Start of File: {file_name} ---\n{chunks[0]}"
                # Add end identifier to the last chunk
                chunks[-1] = f"{chunks[-1]}\n--- End of File: {file_name} ---"

            # Update progress bar for gathering chunks
            for i, _ in enumerate(chunks):
                progress = (i + 1) / len(chunks) * 0.5  # First 50% for gathering
                self.file_picker_button.configure(text=f"Processing... {int(progress * 100)}%")
                self.file_picker_button.update()

            # Stage 2: Generate embeddings and save chunks to the database
            self.conversation_manager.save_chunks_to_db(chunks, file_name)
            self.file_picker_button.configure(text="Processing... 100%")
            self.file_picker_button.update()
        finally:
            # Restore the button after processing is complete
            self.restore_button()

    def split_into_context_aware_chunks(self, content):
        """
        Split the content into context-aware chunks, respecting sentence and paragraph boundaries.
        Each chunk will contain approximately 200 words.
        """
        # First, split into paragraphs
        paragraphs = content.split("\n\n")  # Assuming paragraphs are separated by double newlines

        chunks = []
        current_chunk = ""
        max_words_per_chunk = 200  # Maximum number of words per chunk

        for paragraph in paragraphs:
            # Split the paragraph into sentences
            sentences = re.split(r'(?<=[.!?]) +', paragraph)  # Split by sentences

            for sentence in sentences:
                # Add the sentence to the current chunk
                current_chunk += sentence + " "

                # If the current chunk exceeds the word limit, save it and start a new one
                if len(current_chunk.split()) >= max_words_per_chunk:
                    chunks.append(current_chunk.strip())
                    current_chunk = ""

            # Add the remaining content in the current chunk
            if current_chunk.strip():
                chunks.append(current_chunk.strip())
            current_chunk = ""

        return chunks

    def restore_button(self):
        """
        Restore the file picker button after processing is complete.
        """
        self.file_picker_button.configure(text="Update Memory", fg_color="#000000", hover=True)
        self.file_picker_button.update()

    def detect_encoding(self, file_path):
        """
        Detect the encoding of a file.
        """
        with open(file_path, 'rb') as file:
            raw_data = file.read()
            result = chardet.detect(raw_data)
            return result['encoding']

    def read_file_content(self, file_path):
        """
        Read the content of a file based on its extension.
        """
        file_extension = os.path.splitext(file_path)[1].lower()
        if file_extension == '.pdf':
            with open(file_path, 'rb') as file:
                reader = PyPDF2.PdfReader(file)
                content = ""
                for page in reader.pages:
                    content += page.extract_text()
            return content
        elif file_extension == '.docx':
            doc = docx.Document(file_path)
            content = "\n".join([para.text for para in doc.paragraphs])
            return content
        elif file_extension == '.txt':
            encoding = self.detect_encoding(file_path)
            with open(file_path, 'r', encoding=encoding) as file:
                content = file.read()
            return content
        elif file_extension == '.csv':
            encoding = self.detect_encoding(file_path)
            with open(file_path, 'r', encoding=encoding) as file:
                reader = csv.reader(file)
                content = "\n".join([",".join(row) for row in reader])
            return content
        elif file_extension in ['.py', '.js', '.java', '.html', '.css', '.cpp', '.c', '.sh', '.sql']:
            encoding = self.detect_encoding(file_path)
            with open(file_path, 'r', encoding=encoding) as file:
                content = file.read()
            return content
        else:
            raise ValueError(f"Unsupported file type: {file_extension}")
# END OF FILE: C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\brain\file_picker.py
# END OF FILE: C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\brain\file_picker.py


# START OF FILE: C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\brain\init.py

# END OF FILE: C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\brain\init.py


# START OF FILE: C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\brain\memory_handler.py
# START OF FILE: C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\brain\memory_handler.py
import os
import logging
import numpy as np
from gensim.models import Word2Vec
from gensim.utils import simple_preprocess

# Set up logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S"
)

class MemoryHandler:
    def __init__(self, memory_dir):
        """
        Initialize the MemoryHandler with a specific memory directory.
        The Word2Vec model will be saved in the conversation-specific subfolder.
        """
        self.memory_dir = memory_dir
        self.model_path = os.path.join(self.memory_dir, "word2vec.model")
        self.word2vec_model = None
        self.vector_size = 100  # Ensure this matches the Word2Vec model's vector size
        self.load_or_train_word2vec_model()

    def load_or_train_word2vec_model(self):
        """
        Load the Word2Vec model if it exists in the conversation-specific directory, otherwise train a new one.
        """
        if os.path.exists(self.model_path):
            logging.info("Loading existing Word2Vec model.")
            self.word2vec_model = Word2Vec.load(self.model_path)
        else:
            logging.info("Training new Word2Vec model.")
            # Train a new Word2Vec model with default data
            sentences = [["default", "sentence", "for", "training"]]
            self.word2vec_model = Word2Vec(sentences, vector_size=self.vector_size, window=5, min_count=1, workers=4)
            self.word2vec_model.save(self.model_path)

    def sentence_to_vec(self, sentence):
        """
        Convert a sentence to a vector using Word2Vec.
        Ensure an embedding is always generated, even for short or single-word messages.
        """
        if not self.word2vec_model:
            logging.error("Word2Vec model is not loaded.")
            return None

        try:
            # Preprocess the sentence into words
            words = simple_preprocess(sentence)
            if not words:  # If no words are found, use the entire sentence as a single word
                words = [sentence.strip()]

            # Generate vectors for each word in the sentence
            vectors = []
            for word in words:
                if word in self.word2vec_model.wv:
                    vectors.append(self.word2vec_model.wv[word])
                else:
                    # If the word is not in the vocabulary, generate a random vector
                    vectors.append(np.random.rand(self.vector_size))

            if vectors:
                # Return the average of all word vectors
                return np.mean(vectors, axis=0)
            else:
                # If no valid words are found, return a zero vector
                logging.warning("No valid words found in the sentence for Word2Vec. Returning a zero vector.")
                return np.zeros(self.vector_size)
        except Exception as e:
            logging.error(f"Error converting sentence to vector: {str(e)}")
            return np.zeros(self.vector_size)

    def update_word2vec_model(self, new_sentences):
        """
        Update the Word2Vec model with new sentences.
        """
        if not self.word2vec_model:
            logging.error("Word2Vec model is not loaded.")
            return

        try:
            # Ensure new_sentences is a list of tokenized sentences (list of lists of words)
            if not isinstance(new_sentences, list) or not all(isinstance(sentence, list) for sentence in new_sentences):
                raise ValueError("new_sentences must be a list of tokenized sentences (list of lists of words).")

            # Update the Word2Vec model with new sentences
            self.word2vec_model.build_vocab(new_sentences, update=True)
            self.word2vec_model.train(new_sentences, total_examples=len(new_sentences), epochs=10)
            self.word2vec_model.save(self.model_path)
            logging.info("Word2Vec model updated with new sentences.")
        except Exception as e:
            logging.error(f"Error updating Word2Vec model: {str(e)}")
# END OF FILE: C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\brain\memory_handler.py
# END OF FILE: C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\brain\memory_handler.py


# START OF FILE: C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\brain\typestreaming.py
import os
import datetime
import csv
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
from openai import OpenAI as Client

class ConversationEventHandler(FileSystemEventHandler):
    def __init__(self, manager):
        self.manager = manager

    def on_modified(self, event):
        if event.src_path == self.manager.conversation_csv_path:
            self.manager.process_new_messages()

class ConversationManager:
    def __init__(self):
        self.memory_dir = os.path.join(os.path.dirname(__file__), "Memory")
        os.makedirs(self.memory_dir, exist_ok=True)
        self.conv_folder = None
        self.conversation_csv_path = None
        self.context = []
        self.unique_entries = set()
        self.MODEL_NAME = "gpt-4"
        self.OPEN_ROUTER_API_KEY = None
        self.client = None
        self.observer = None
        self.last_modified_time = None

        self.init_conversation()

    def init_conversation(self):
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        self.conv_folder = os.path.join(self.memory_dir, f"memory_{timestamp}")
        os.makedirs(self.conv_folder, exist_ok=True)
        self.conversation_csv_path = os.path.join(self.conv_folder, "conversations.csv")
        
        if not os.path.exists(self.conversation_csv_path):
            with open(self.conversation_csv_path, "w", encoding='utf-8', newline='') as f:
                writer = csv.writer(f)
                writer.writerow(["Timestamp", "Message", "Summary"])
        self.load_conversation_from_csv()
        self.start_watching_file()

    def load_conversation_from_csv(self):
        current_modified_time = os.path.getmtime(self.conversation_csv_path)
        if self.last_modified_time is None or self.last_modified_time < current_modified_time:
            self.last_modified_time = current_modified_time
            self.context = []
            self.unique_entries = set()
            if os.path.exists(self.conversation_csv_path):
                with open(self.conversation_csv_path, "r", encoding='utf-8', newline='') as f:
                    reader = csv.reader(f)
                    next(reader)  # Skip header row
                    for row in reader:
                        timestamp = row[0]
                        message = row[1]
                        summary = row[2]
                        entry_key = (timestamp, message)
                        if entry_key not in self.unique_entries:
                            self.unique_entries.add(entry_key)
                            self.context.append((timestamp, message, summary))

    def append_to_conversation(self, user_query, ai_response=None, timestamp=None):
        if not timestamp:
            timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        if ai_response is not None:
            combined_message = f"User: {user_query}\nAI: {ai_response}"
        else:
            combined_message = f"User: {user_query}"
        
        summary = self.summarize(combined_message)
        
        entry_key = (timestamp, combined_message)
        if entry_key not in self.unique_entries:
            self.unique_entries.add(entry_key)
            self.context.append((timestamp, combined_message, summary))
            self.save_conversation_to_csv(combined_message, summary, timestamp)

    def summarize(self, message):
        if len(message.split()) <= 50:
            return message
        
        summary_prompt = f"Summarize the following message in 50 words or less:\n\n{message}"
        
        try:
            completion = self.client.chat.completions.create(
                model=self.MODEL_NAME,
                messages=[
                    {"role": "system", "content": "You are an AI assistant tasked with summarizing messages."},
                    {"role": "user", "content": summary_prompt}
                ],
                extra_headers={
                    "HTTP-Referer": "your_site_url",  # Replace with your site URL
                    "X-Title": "your_app_name",       # Replace with your app name
                }
            )
            if completion.choices and completion.choices[0].message:
                return completion.choices[0].message.content.strip()
            else:
                print("Error summarizing message: No message found in API response.")
                return message
        except Exception as e:
            print(f"Error summarizing message: {str(e)}")
            return message

    def process_query(self, user_message):
        self.load_conversation_from_csv()

        self.append_to_conversation(user_message)

        conversation_history = [
            {"role": "system", "content": "You are an AI assistant. I will remember our conversation and provide relevant responses based on previous interactions."}
        ]

        for timestamp, message, summary in self.context:
            if "\n" in message:
                user_part, ai_part = message.split("\n", 1)
                user_part = user_part.replace("User: ", "").strip()
                ai_part = ai_part.replace("AI: ", "").strip()
                conversation_history.append({"role": "user", "content": user_part})
                conversation_history.append({"role": "assistant", "content": ai_part})
            else:
                user_part = message.replace("User: ", "").strip()
                conversation_history.append({"role": "user", "content": user_part})

        try:
            completion = self.client.chat.completions.create(
                model=self.MODEL_NAME,
                messages=conversation_history,
                extra_headers={
                    "HTTP-Referer": "your_site_url",  # Replace with your site URL
                    "X-Title": "your_app_name",       # Replace with your app name
                }
            )
            if completion.choices and completion.choices[0].message:
                response_message = completion.choices[0].message.content
                self.append_to_conversation(user_message, response_message)
                return response_message
            else:
                print("Error processing query: No message found in API response.")
                return None
        except Exception as e:
            print(f"Error processing query: {str(e)}")
            return None

    def process_new_messages(self):
        self.load_conversation_from_csv()
        self.cleanup_csv()

    def cleanup_csv(self):
        # Create a temporary file to store valid rows
        temp_csv_path = self.conversation_csv_path + ".tmp"
        with open(self.conversation_csv_path, "r", encoding='utf-8', newline='') as f_in, open(temp_csv_path, "w", encoding='utf-8', newline='') as f_out:
            reader = csv.reader(f_in)
            writer = csv.writer(f_out)
            header = next(reader)
            writer.writerow(header)  # Write the header to the temp file
            
            for row in reader:
                timestamp = row[0]
                message = row[1]
                summary = row[2]
                if "\n" in message:
                    user_part, ai_part = message.split("\n", 1)
                    if user_part.strip().startswith("User: ") and ai_part.strip().startswith("AI: "):
                        writer.writerow(row)
                else:
                    # If the row does not contain a newline, it might be a user message without AI response
                    if message.strip().startswith("User: "):
                        pass  # Skip this row as it's incomplete

        # Replace the original file with the temp file
        os.replace(temp_csv_path, self.conversation_csv_path)
        self.load_conversation_from_csv()

    def clear_conversation(self):
        if self.conv_folder:
            for root, dirs, files in os.walk(self.conv_folder, topdown=False):
                for name in files:
                    os.remove(os.path.join(root, name))
                for name in dirs:
                    os.rmdir(os.path.join(root, name))
            os.rmdir(self.conv_folder)
        
        self.init_conversation()
        self.context = []
        self.unique_entries = set()

    def set_model_name(self, model_name):
        self.MODEL_NAME = model_name
        self.update_client()

    def set_openrouter_api_key(self, api_key):
        self.OPEN_ROUTER_API_KEY = api_key
        self.update_client()

    def update_client(self):
        if self.MODEL_NAME and self.OPEN_ROUTER_API_KEY:
            self.client = Client(
                base_url="https://openrouter.ai/api/v1",
                api_key=self.OPEN_ROUTER_API_KEY,
            )

    def start_watching_file(self):
        if self.conversation_csv_path:
            event_handler = ConversationEventHandler(self)
            self.observer = Observer()
            self.observer.schedule(event_handler, os.path.dirname(self.conversation_csv_path), recursive=False)
            self.observer.start()

    def stop_watching_file(self):
        if self.observer:
            self.observer.stop()
            self.observer.join()

    def save_conversation_to_csv(self, combined_message, summary, timestamp):
        with open(self.conversation_csv_path, "a", encoding='utf-8', newline='') as f:
            writer = csv.writer(f)
            writer.writerow([timestamp, combined_message, summary])

# Define the conversation manager instance
conversation_manager = ConversationManager()
conversation_manager.set_model_name("gpt-4")  # Set your desired model name
conversation_manager.set_openrouter_api_key("your_openrouter_api_key")  # Set your OpenRouter API key
conversation_manager.init_conversation()

# Example usage:
user_query = "Tell me a story about a brave knight who saved a kingdom from a dragon."
response = conversation_manager.process_query(user_query)
print(f"AI Response: {response}")
# END OF FILE: C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\brain\typestreaming.py


# START OF FILE: C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\brain\web_agent.py
# START OF FILE: C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\brain\web_agent.py
import os
import logging
import re
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.common.exceptions import TimeoutException, WebDriverException
import time
from openai import OpenAI
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from .memory_handler import MemoryHandler
from gensim.utils import simple_preprocess
import sqlite3
import datetime
import json

# Set up logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S"
)

class WebAgent:
    def __init__(self, conversation_manager):
        """
        Initialize the WebAgent with a reference to the ConversationManager.
        """
        self.conversation_manager = conversation_manager
        self.client = OpenAI(
            base_url="https://openrouter.ai/api/v1",
            api_key=self.conversation_manager.OPEN_ROUTER_API_KEY,
        )
        self.memory_handler = MemoryHandler(self.conversation_manager.memory_dir)

    def is_url(self, text):
        """
        Check if the input text contains a URL.
        """
        url_pattern = re.compile(
            r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'
        )
        return bool(url_pattern.search(text))

    def visit_url_with_selenium(self, url):
        """
        Visit the URL using Selenium and Chrome, and return the page source.
        """
        # Set up Chrome options
        chrome_options = Options()
        chrome_options.add_argument("--disable-gpu")
        chrome_options.add_argument("--no-sandbox")
        chrome_options.add_argument("--disable-dev-shm-usage")
        chrome_options.add_argument("--headless")  # Run in headless mode (no GUI)

        try:
            # Initialize the Chrome driver
            driver = webdriver.Chrome(options=chrome_options)
            driver.set_page_load_timeout(30)  # Set timeout for page load
            logging.info(f"Visiting URL: {url}")
            driver.get(url)  # Open the URL in Chrome
            time.sleep(5)  # Wait for the page to load (adjust as needed)

            # Get the page source after it has loaded
            page_source = driver.page_source
            driver.quit()  # Close the browser
            return page_source
        except (TimeoutException, WebDriverException) as e:
            logging.error(f"Error visiting URL {url}: {str(e)}")
            return None

    def scrape_website_content(self, url):
        """
        Scrape the content of a website and extract relevant information.
        """
        # Visit the URL and get the page source
        page_source = self.visit_url_with_selenium(url)
        if not page_source:
            return None

        try:
            # Parse the page source with BeautifulSoup
            soup = BeautifulSoup(page_source, 'html.parser')

            # Extract the title
            title = soup.title.string if soup.title else "No Title"

            # Extract all text content
            text_content = soup.get_text(separator="\n")

            # Extract specific elements (e.g., headings, paragraphs) and convert to markdown
            markdown_content = f"# {title}\n\n"
            for heading in soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6']):
                markdown_content += f"{'#' * int(heading.name[1])} {heading.text}\n\n"
            for paragraph in soup.find_all('p'):
                markdown_content += f"{paragraph.text}\n\n"

            # Organize the scraped content
            scraped_data = {
                'title': title,
                'text_content': text_content,
                'markdown_content': markdown_content,
            }
            return scraped_data
        except Exception as e:
            logging.error(f"Error parsing website content: {str(e)}")
            return None

    def save_scraped_content(self, url, content):
        """
        Save the scraped content to the database in markdown format.
        """
        if not content:
            return "No content to save."

        try:
            # Convert the content to a string (e.g., JSON format)
            content_str = json.dumps(content, ensure_ascii=False)

            # Generate an embedding for the content
            embedding = self.memory_handler.sentence_to_vec(content_str)

            # Save to the database
            conn = sqlite3.connect(self.conversation_manager.db_path)
            cursor = conn.cursor()
            cursor.execute('''
                INSERT INTO embeddings (timestamp, content, embedding, source_type)
                VALUES (?, ?, ?, ?)
            ''', (
                datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                content['markdown_content'],
                json.dumps(embedding.tolist()) if embedding is not None else None,
                "SCRAPED_INFO"  # Indicate that this is website content
            ))
            conn.commit()
            conn.close()
            logging.info(f"Scraped content saved to the database for URL: {url}")
            return "Scraped content saved successfully."
        except Exception as e:
            logging.error(f"Error saving scraped content: {str(e)}")
            return "An error occurred while saving the scraped content."

    def process_webpage(self, url):
        """
        Process a webpage by visiting it with Selenium, scraping its content, and saving it to the database.
        """
        try:
            # Scrape the webpage content
            scraped_content = self.scrape_website_content(url)
            if not scraped_content:
                return "Failed to scrape the webpage."

            # Save the scraped content to the database
            result = self.save_scraped_content(url, scraped_content)
            return result
        except Exception as e:
            logging.error(f"Error processing webpage: {str(e)}")
            return "An error occurred while processing the webpage."
# END OF FILE: C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\brain\web_agent.py
# END OF FILE: C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\brain\web_agent.py


# START OF FILE: C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\brain\Appendix\append_scripts.py
import os

def generate_combined_file(source_dir, output_file):
    """Generate a combined sitemap and script content file."""
    supported_extensions = {".py", ".js", ".html", ".css", ".java"}  # Supported script extensions
    excluded_folders = [
        os.path.join(source_dir, "brain", "Memory"),
        os.path.join(source_dir, "Project Overview"),
        os.path.join(source_dir, "gui")  # Exclude the 'gui' folder
    ]  # Folders to exclude

    with open(output_file, "w", encoding="utf-8") as outfile:
        # Step 1: Generate the sitemap
        outfile.write("No comments # in code, don't print the site map. Only show corrected script. Sitemap of Directory: Odin 2\n")
        outfile.write("=" * 50 + "\n")
        for root, dirs, files in os.walk(source_dir):
            # Skip excluded folders
            if any(root.startswith(folder) for folder in excluded_folders):
                continue

            # Write folder name
            relative_path = os.path.relpath(root, source_dir)
            outfile.write(f"\n[Folder] {relative_path}\n")
            outfile.write("-" * 50 + "\n")
            for file in files:
                if not file.endswith(".txt"):  # Skip .txt files
                    file_path = os.path.join(root, file)
                    outfile.write(f"  {file_path}\n")

        outfile.write("\n" + "=" * 50 + "\n\n")

        # Step 2: Append script contents
        outfile.write("Script Contents\n")
        outfile.write("=" * 50 + "\n")
        for root, _, files in os.walk(source_dir):
            # Skip excluded folders
            if any(root.startswith(folder) for folder in excluded_folders):
                continue

            for file in files:
                file_path = os.path.join(root, file)
                # Check file extension
                if os.path.splitext(file)[1] in supported_extensions:
                    try:
                        with open(file_path, "r", encoding="utf-8") as infile:
                            # Write a header for each file
                            outfile.write(f"\n# START OF FILE: {file_path}\n")
                            outfile.write(infile.read())
                            outfile.write(f"\n# END OF FILE: {file_path}\n\n")
                            print(f"Appended: {file_path}")
                    except Exception as e:
                        print(f"Error reading {file_path}: {e}")

if __name__ == "__main__":
    source_directory = r"C:\Users\Sean Craig\Desktop\AI Python Tools\Odin"
    output_file_path = r"C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\brain\Appendix\combined_sitemap_and_scripts.txt"
    
    generate_combined_file(source_directory, output_file_path)
    print(f"\nSitemap and script contents have been saved to {output_file_path}")

# END OF FILE: C:\Users\Sean Craig\Desktop\AI Python Tools\Odin\brain\Appendix\append_scripts.py

